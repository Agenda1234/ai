import os
from openai import OpenAI

# ====================== 1. é…ç½®é˜¿é‡Œé€šä¹‰åƒé—®API ======================
DASHSCOPE_API_KEY = "sk-111"
os.environ["DASHSCOPE_API_KEY"] = DASHSCOPE_API_KEY

# åˆå§‹åŒ–åƒé—®å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆä»…æœªå‘½ä¸­æ—¶è°ƒç”¨ï¼‰
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# ====================== 2. æ ¸å¿ƒå‡½æ•°ï¼šä¼˜å…ˆè¯»å‘é‡åº“ï¼Œå‘½ä¸­ç›´æ¥è¿”å›ï¼Œæœªå‘½ä¸­è°ƒç”¨å¤§æ¨¡å‹ ======================
def retrieve_or_answer(query: str, vectorstore, similarity_threshold: float = 0.5):
    """
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. ä»å‘é‡åº“æ£€ç´¢ï¼Œå‘½ä¸­ï¼ˆç›¸ä¼¼åº¦â‰¥é˜ˆå€¼ï¼‰â†’ ç›´æ¥è¿”å›æ£€ç´¢ç»“æœï¼›
    2. æœªå‘½ä¸­ â†’ è°ƒç”¨å¤§æ¨¡å‹ç”¨é€šç”¨çŸ¥è¯†å›ç­”ã€‚
    :param query: ç”¨æˆ·æŸ¥è¯¢é—®é¢˜
    :param vectorstore: Chromaå‘é‡åº“å¯¹è±¡
    :param similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
    :return: æœ€ç»ˆå›ç­”
    """
    # æ­¥éª¤1ï¼šä»å‘é‡åº“æ£€ç´¢ï¼ˆå¸¦ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰
    results = vectorstore.similarity_search_with_score(query=query, k=3)
    
    # æ­¥éª¤2ï¼šè¿‡æ»¤æœ‰æ•ˆç»“æœï¼ˆç›¸ä¼¼åº¦â‰¥é˜ˆå€¼ï¼‰
    valid_results = [(doc, score) for doc, score in results if score >= similarity_threshold]
    
    # åˆ†æ”¯1ï¼šå‘½ä¸­ â†’ ç›´æ¥è¿”å›æ£€ç´¢åˆ°çš„å†…å®¹
    if valid_results:
        # æ‹¼æ¥æ‰€æœ‰æœ‰æ•ˆæ£€ç´¢ç»“æœ
        retrieved_content = "\n\n".join([
            f"ã€ç›¸å…³å†…å®¹ {i+1}ï¼ˆç›¸ä¼¼åº¦ï¼š{score:.2f}ï¼‰ã€‘\n{doc.page_content}"
            for i, (doc, score) in enumerate(valid_results)
        ])
        return f"âœ… ä»æ–‡æ¡£ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼š\n{retrieved_content}"
    
    # åˆ†æ”¯2ï¼šæœªå‘½ä¸­ â†’ è°ƒç”¨å¤§æ¨¡å‹å›ç­”
    else:
        try:
            completion = client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„åŠ©æ‰‹ï¼Œç”¨é€šç”¨çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"},
                    {"role": "user", "content": query},
                ]
            )
            answer = completion.choices[0].message.content
            return f"ğŸ“ æœªä»æ–‡æ¡£ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä»¥ä¸‹æ˜¯é€šç”¨å›ç­”ï¼š\n{answer}"
        except Exception as e:
            return f"âŒ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼š{str(e)}"

# ====================== 3. åŠ è½½PDF+æ‹†åˆ†+å‘é‡åŒ–+å­˜å…¥å‘é‡åº“ ======================
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.dashscope import DashScopeEmbeddings
from langchain.vectorstores import Chroma

# åŠ è½½PDF
loader = PyPDFLoader("agendadu.pdf")
pages = loader.load_and_split()
print(f"âœ… PDFåŠ è½½å®Œæˆï¼Œæ€»é¡µæ•°: {len(pages)}")

# æ‹†åˆ†æ–‡æœ¬
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50, separator="\n")
docs = text_splitter.split_documents(pages)
print(f"âœ… æ–‡æœ¬æ‹†åˆ†å®Œæˆï¼Œæ€»æ®µè½æ•°: {len(docs)}")

# åˆå§‹åŒ–é˜¿é‡ŒåµŒå…¥æ¨¡å‹
embeddings = DashScopeEmbeddings(model="text-embedding-v2", dashscope_api_key=DASHSCOPE_API_KEY)

# å­˜å…¥å‘é‡åº“ï¼ˆæŒä¹…åŒ–ï¼‰
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embeddings,
    collection_name="agenda",
    persist_directory="./chroma_db"
)
vectorstore.persist()
print("âœ… æ–‡æœ¬å‘é‡åŒ–å®Œæˆï¼Œå·²å­˜å…¥Chromaå‘é‡æ•°æ®åº“")

# ====================== 4. æµ‹è¯•ï¼šå‘½ä¸­è¿”å›æ£€ç´¢ç»“æœï¼Œæœªå‘½ä¸­è°ƒç”¨å¤§æ¨¡å‹ ======================
# æµ‹è¯•1ï¼šå‘½ä¸­çš„æŸ¥è¯¢ï¼ˆPDFé‡Œæœ‰ç›¸å…³å†…å®¹ï¼‰â†’ ç›´æ¥è¿”å›æ£€ç´¢ç»“æœ
query1 = "ä»–åœ¨å“ªå®¶ä¼ä¸šå·¥ä½œè¿‡"
print(f"\nğŸ” æŸ¥è¯¢1ï¼š{query1}")
answer1 = retrieve_or_answer(query1, vectorstore, similarity_threshold=0.5)
print(answer1)

# æµ‹è¯•2ï¼šæœªå‘½ä¸­çš„æŸ¥è¯¢ï¼ˆPDFé‡Œæ— ç›¸å…³å†…å®¹ï¼‰â†’ è°ƒç”¨å¤§æ¨¡å‹å›ç­”
query2 = "2025å¹´è‹±é›„è”ç›ŸS15å† å†›æ˜¯è°"
print(f"\nğŸ” æŸ¥è¯¢2ï¼š{query2}")
answer2 = retrieve_or_answer(query2, vectorstore, similarity_threshold=0.5)
print(answer2)
