import os
from openai import OpenAI

# é…ç½®åƒé—®API
DASHSCOPE_API_KEY = ""
os.environ["DASHSCOPE_API_KEY"] = DASHSCOPE_API_KEY

client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# æ ¸å¿ƒæ£€ç´¢å‡½æ•°ï¼ˆæ–°å¢é˜ˆå€¼å±•ç¤ºé€»è¾‘ï¼‰
def retrieve_or_answer(query: str, vectorstore, distance_threshold: float = 1.0):
    """
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. Chromaè¿”å›çš„æ˜¯ä½™å¼¦è·ç¦»ï¼ˆ0-2ï¼‰ï¼Œè·ç¦»â‰¤é˜ˆå€¼æ‰è§†ä¸ºå‘½ä¸­ï¼ˆè·ç¦»è¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜ï¼‰ï¼›
    2. æœªå‘½ä¸­æ—¶å±•ç¤ºå½“å‰ä½¿ç”¨çš„é˜ˆå€¼ï¼Œæ–¹ä¾¿æ’æŸ¥ï¼›
    """
    results = vectorstore.similarity_search_with_score(query=query, k=3)
    valid_results = [(doc, score) for doc, score in results if score <= distance_threshold]
    
    if valid_results:
        retrieved_content = "\n\n".join([
            f"ã€ç›¸å…³å†…å®¹ {i+1}ï¼ˆè·ç¦»ï¼š{score:.2f}ï¼‰ã€‘\n{doc.page_content}"
            for i, (doc, score) in enumerate(valid_results)
        ])
        return f"âœ… ä»æ–‡æ¡£ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼š\n{retrieved_content}"
    else:
        # æœªå‘½ä¸­æ—¶ï¼Œè¡¥å……å±•ç¤ºé˜ˆå€¼å’Œæ£€ç´¢åˆ°çš„æœ€ä½è·ç¦»ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        # è·å–æ‰€æœ‰æ£€ç´¢ç»“æœçš„è·ç¦»ï¼Œå±•ç¤ºæœ€æ¥è¿‘çš„é‚£ä¸ª
        if results:
            min_distance = min([score for _, score in results])
            hint = f"ï¼ˆå½“å‰è·ç¦»é˜ˆå€¼ï¼š{distance_threshold}ï¼Œæ£€ç´¢åˆ°çš„æœ€å°è·ç¦»ï¼š{min_distance:.2f}ï¼‰"
        else:
            hint = f"ï¼ˆå½“å‰è·ç¦»é˜ˆå€¼ï¼š{distance_threshold}ï¼Œæœªæ£€ç´¢åˆ°ä»»ä½•å†…å®¹ï¼‰"
        
        try:
            completion = client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„åŠ©æ‰‹ï¼Œç”¨é€šç”¨çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"},
                    {"role": "user", "content": query},
                ]
            )
            answer = completion.choices[0].message.content
            return f"ğŸ“ æœªä»æ–‡æ¡£ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ {hint}ï¼Œä»¥ä¸‹æ˜¯é€šç”¨å›ç­”ï¼š\n{answer}"
        except Exception as e:
            return f"âŒ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥ {hint}ï¼š{str(e)}"

# åŠ è½½PDF+æ‹†åˆ†ï¼ˆæ–°ç‰ˆå¯¼å…¥è·¯å¾„ï¼‰
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.embeddings.dashscope import DashScopeEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document

# åŠ è½½PDF
loader = PyPDFLoader("agendadu.pdf")
raw_pages = loader.load()
print(f"âœ… PDFåŠ è½½å®Œæˆï¼ŒåŸå§‹é¡µæ•°: {len(raw_pages)}")

# æ ‡å‡†åŒ–Document
pages = []
for page in raw_pages:
    content = page.page_content.strip() if hasattr(page, "page_content") else ""
    if content:
        pages.append(Document(page_content=content, metadata=page.metadata if hasattr(page, "metadata") else {}))

# æ‹†åˆ†æ–‡æœ¬
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50, separator="\n")
docs = text_splitter.split_documents(pages)

# å»é‡
unique_docs = []
seen_content = set()
for doc in docs:
    content = doc.page_content.strip()
    if content not in seen_content:
        seen_content.add(content)
        unique_docs.append(doc)
docs = unique_docs
print(f"âœ… æ–‡æœ¬æ‹†åˆ†+å»é‡å®Œæˆï¼Œæ€»æ®µè½æ•°: {len(docs)}")

# å‘é‡åŒ–+å­˜å‚¨
embeddings = DashScopeEmbeddings(model="text-embedding-v2", dashscope_api_key=DASHSCOPE_API_KEY)
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embeddings,
    collection_name="agenda",
    persist_directory="./chroma_db"
)
vectorstore.persist()
print("âœ… æ–‡æœ¬å‘é‡åŒ–å®Œæˆï¼Œå·²å­˜å…¥Chromaå‘é‡æ•°æ®åº“")

# æµ‹è¯•
query1 = "ä»–å“ªå¹´åœ¨å“ªå®¶ä¼ä¸šå·¥ä½œè¿‡"
print(f"\nğŸ” æŸ¥è¯¢1ï¼š{query1}")
print(retrieve_or_answer(query1, vectorstore, distance_threshold=1.1))

query2 = "ä½ æ˜¯è°"
print(f"\nğŸ” æŸ¥è¯¢2ï¼š{query2}")
<<<<<<< HEAD
print(retrieve_or_answer(query2, vectorstore, distance_threshold=1.0))
=======
answer2 = retrieve_or_answer(query2, vectorstore, similarity_threshold=0.5)
print(answer2)
>>>>>>> 34d4026955bdd258d2df7cd5e8960e6d2c0b5c10
